{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required directories\n",
    "\n",
    "import os\n",
    "import gzip\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the directory containing the .gz files to unzip the dowloaded .gz files\n",
    "dir_path = '../CONTRIBUTING.mddata/raw'\n",
    "\n",
    "# Loop through each .gz file in the directory\n",
    "for filename in os.listdir(dir_path):\n",
    "    if filename.endswith('.gz'):\n",
    "        \n",
    "        # Open .gz file and extract contents to a new file\n",
    "        with gzip.open(os.path.join(dir_path, filename), 'rb') as f_in:\n",
    "            with open(os.path.join(dir_path, filename[:-3]), 'wb') as f_out:\n",
    "                f_out.write(f_in.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read json files in batch\n",
    "# Set the directory containing the JSON files\n",
    "dir_path = '../data/raw'\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Loop through each JSON file in the directory\n",
    "for filename in os.listdir(dir_path):\n",
    "    if filename.endswith('.json'):\n",
    "        \n",
    "        # Read JSON file into a DataFrame\n",
    "        with open(os.path.join(dir_path, filename), 'r') as f:\n",
    "            df = pd.read_json(f, lines=True)\n",
    "        \n",
    "        # Append DataFrame to list\n",
    "        dfs.append(df)\n",
    "        print('file:', filename, ' Done!')\n",
    "\n",
    "# Concatenate all DataFrames in the list into one DataFrame\n",
    "final_df = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_df = pd.read_csv('../data/raw/1.csv', index_col=0)\n",
    "final_df = pd.read_json('../data/raw/2023-03-17-23.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "drop_df = final_df.drop(['payload', 'public', 'org'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some data cleaning and joining\n",
    "expanded_actor_df = pd.json_normalize(drop_df['actor'])\n",
    "expanded_actor_df = expanded_actor_df.rename(columns={'id':'actor_id',\n",
    "                                                      'url':'actor_url'})\n",
    "actor_df = expanded_actor_df.drop(['login', 'display_login', 'gravatar_id',\n",
    "                                   'actor_url', 'avatar_url'], axis=1)\n",
    "\n",
    "expanded_repo_df = pd.json_normalize(drop_df['repo'])\n",
    "expanded_repo_df = expanded_repo_df.rename(columns={'id':'repo_id',\n",
    "                                                    'url':'repo_url'})\n",
    "repo_df = expanded_repo_df.drop(['name', 'repo_url'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the final raw df\n",
    "df_main = drop_df.reset_index()\n",
    "df_final = df_main.drop(['actor', 'repo', 'index'], axis=1)\n",
    "\n",
    "merged_df_final = pd.concat([df_final,\n",
    "                             actor_df,\n",
    "                             repo_df], axis=1)\n",
    "merged_df_final.to_csv('../data/raw/raw_data-23.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pds = []\n",
    "for i in range(0, 24):\n",
    "    name = '../data/raw/raw_data-'+str(i)+'.csv'\n",
    "    df = pd.read_csv(name, index_col = 0)\n",
    "    pds.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.concat(pds, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv('../data/raw/raw_data-main.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = df_raw.sample(n=2000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.to_csv('../data/raw/raw_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsci532",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
